\documentclass[11pt]{article}

\usepackage{fullpage,times,namedplus,pgf}
\usepackage{enumitem}
\usepackage{amsmath,amssymb}
\usepackage{kbordermatrix}% http://www.hss.caltech.edu/~kcb/TeX/kbordermatrix.sty

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\E}{\mathbb{E}}


\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\newcommand{\myroot}{\ensuremath{\mathrm{root}}}

\newcommand{\context}[1]{\ensuremath{\mathrm{con}(#1)}}
\newcommand{\psn}{\ensuremath{\mathrm{pos}}}

\newcommand{\birth}{\ensuremath{\mathcal{B}}}
\newcommand{\death}{\ensuremath{\mathcal{D}}}
\newcommand{\expansion}{\ensuremath{\mathcal{E}}}
\newcommand{\contraction}{\ensuremath{\mathcal{C}}}
\newcommand{\merging}{\ensuremath{\mathcal{M}}}
\newcommand{\separating}{\ensuremath{\mathcal{S}}}
\newcommand{\child}[1]{\ensuremath{\mathrm{child}(#1)}}
\newcommand{\tth}{\ensuremath{^\mathrm{th}}}

\newcommand\halfopen[2]{\ensuremath{[#1,#2)}}

\title{A model of epigenome evolution}
\author{Jianghan Qu \and Andrew D. Smith}

%%% ADS Notes:
%%
%%% (1) We need to define operationally an epigenome as a binary
%%% sequence, and in the introduction we need to explain this.
%%
%%% (2) We need to make sure that we use the terms "position" and
%%% "site" consistently. Same for coordinate?
%%
%%% (3) The term "jump" is not defined
%%
%%% (4) The term "context" is not defined
%%
%%% (5) The symbol "Delta" is used in two places in two ways

\begin{document}

\maketitle

\begin{abstract}
  Epigenetic marks along the mammalian genome are organized into
  alternating genomic domains bearing and lacking the mark. The
  location and size of domains enriched for an epigenetic mark are
  indicative of the presence, function and activity of regulatory
  elements and the chromatin states. Comparative epigenomic studies
  aim to resolve the evolutionary history of regulatory elements by
  comparing epigenomic profiles in multiple species.  However,
  computational methods for comparing epigenetic marks at high
  resolution, inferring evolution rates along different phylogenetic
  lineages and reconstructing the evolutionary history are still
  limited.  In this study, we aim to establish a simulation, sampling
  and inference framework for studying the evolution of the genomic
  distribution of an epigenetic from the profiles of multiple extant
  species.  We model the profile of an epigenetic mark in a species
  with a two-state Markov chain, and model the evolution of an
  epigenomic sequence with a continuous-time Markov chain, where
  instantaneous transition rates at a site is dependent on the
  contemporary states of its neighboring sites. We use a MCMC sampling
  method for estimating the context-dependent transition rates and
  inferring the evolutionary history that lead to diverse profiles in
  extant species from a common ancestral epigenome.  We show with
  applications to DNA methylation and histone modification profiles
  that our methods can reveal both genome-wide evolutionary features
  through estimates of the model parameters and high-resolution
  evolutionary patterns in local regions through posterior sampling of
  the evolutionary history.
\end{abstract}

\section{Introduction}

%%% First paragraph intro about epigenomes
The epigenome of a mammalian cell reflects much of the complexity we
associate with cell phenotype and behaviors \cite{}. Individual
epigenomic marks, for example a histone modification, may be viewed
from a simpler perspective as contiguous genomic intervals where the
presence or absense of that mark is associated with genomic
function. Intervals of the genome that have a high density of H3K9me3
are often associated with condensed chromatin state and silencing of
genes within those intervals
\cite{nakayama2001role}. Genomic intervals with high
density of H3K4me3, on the other hand, are associated with
accessibility by transcription factors and are associated with gene
promoters \cite{santos2002active}. So despite the complexity often
ascribed to the mammalian epigenome \cite{bernstein2007mammalian},
studies focusing on individual epigenomic modifications have been
highly successful in elucidating transcriptional regulation in a
variety of systems \cite{martin2005diverse}.
%%% Liz: View on single nucleotides
%%% "Prescense of certain epigenomic markers could be analogously
%%% identified at each individual nucleotide.
%%% For example, cytosines' gaining methyl-group
%%% or not naturally defines the binary state of each cytosine site. The
%%% non-cytosine nucleotides can be regarded as ``missing data'', whose
%%% states indicate whether or not the methylation marker is more likely to
%%% occur if the cytosines are observersed at same postions.
%%% Histone modification state of single nucleotide also implies such
%%% posterior likelihood of wrapping around nucleosome of certain marker,
%%% even though the presence of histones is not known. "

%%% Need to cite work that has boiled down the complexity of
%%% epigenomes to simpler ``functional'' states, like ``open''
%%% ``poised, silenced, ``actively transcribed'', etc.

%%% Need to describe birth, death, etc.
One challenge in modeling epigenome evolution is that desirable models
should account for the inherent auto-correlation of epigenomic state
along the genome. The most well known models of molecular evolution,
applied to amino acids or nucleotides, treat each site as evolving
independently -- a simplifying assumption that has proven very useful.
When models allow for dependencies between sites, we additionally hope
that those dependencies can be interpreted.

%%% Summary and timeline of existing work
\citetext{pedersen1998codon} examined the problem of modeling
evolution at the codon level and designed an approach capable of
describing CpG depression across codon boundaries, a form of
interdependence between adjacent codons. With similar motivation,
\citetext{jensen2000probabilistic} examined the properties of
evoluationary models for which the stationary distribution on
sequences naturally exhibits particular frequencies of dinucleotides.
The result was an approach to model the evolution of an individual
nucleotide as a function of that nucleotide's neighbors in a way that
induces a Markov process on the stationary distribution.
%%% Need to talk about the sufficient condition given by J-P (2000)

%%% Need to relate our work back to the phylo-HMM stuff, particularly
%%% because that work was aware of the chain graph perspective, and
%%% our ``states'' are defined analogously to the generalization from
%%% the Koller-Friedman book.
Our goal of modeling the evolution of an epigenome can be viewed in
analogy with phylogenetic hidden Markov models \cite{}. The phastCons
algorithm \cite{} is the best known variant of phylogenetic HMM, and
has dramatically impacting the field of comparative genomics by
providing a general approach to model ``conserved'' genomic intervals
for a set of species. The states of a simple phylogenetic HMM
correspond to alternating conserved and non-conserved intervals of
aligned genomes. The generalization associates a binary state label
with each nucleotide in each species and presents algorithmic
challenges when viewed generally as a chain graph
\cite{koller2009probabilistic}.

The remainder of this paper is organized as follows. We first describe
our model for epigenome evolution as an adaptation of the principles
introduced by \citetext{jensen2000probabilistic} and use simulation fo
explore model parameterization. Then we explain how to inferences are
made in the context of this model, using simulation to demonstrate the
accuracy of our procedures. Finally, we apply this model on an
existing data set.

\section{The model}

\subsection{Biological assumptions and desired model properties}
\label{biodefs}

%%% Need to cover the issues here of what it means for a methylome,
%%% what it means for ATAC, what it means for histone mods.
We assume that the epigenome is a sequence of binary states (``0'' and ``1'')
super-imposed on the genome. This assumption is restrictive, but it
allows us to consider the epigenome from either the perspective of an
individual epigenomic modification, or as reflecting a particular type
of functional interval. One example of former is a sequence of binary
variables corresponding to the presence or absence of a H3K27me3.
Another example is a binary variable to indicate accessibility, as
determined by a particular assay. An example of a functionally-defined
binary variable may be ``accessible'' or ``enhancer,'' both of which
can be associated with different epigenomic modifications, but are
known to be organized as contiguous intervals. Epigenomic state is
correlated along the genome as a reflection of the organization of the
epigenome into contiguous intervals.

Most types of data that inform us about the epigenome are based on
sequencing, and usually based on density of mapped reads (e.g. from
ChIP-seq or ATAC-seq). Often these data are summarized in
non-overlapping ``bins'' through the genome. When we refer to a
position in the epigenome, we assume that such position corresponds in
a meaningful way to either individual nucleotide positions
in the genome, or appropriate bins. We only require that the
neighboring relations are preserved.

% Move to later
%Let epigenome $s$ be the sequence $s=s_1s_2\cdots s_N$ with $s_i$
%denoting the state at position $i$.
%%%%
%As a graphical model, neighboring sites are connected with undirected
%edges. An epigenome $s$ evolves over time, but we assume the
%stationary distribution for the epigenome has a Gibbs distribution
%that factorizes over pairs of neighboring sites:
%\begin{equation}\label{eqn:stationary}
%  \Pr(s) = \frac{1}{Z} \exp\big\{\phi(s_1) +\sum_{n=1}^{N-1}\phi(s_n, s_{n+1}) + \phi(s_N)\big\}.
%\end{equation}
%An equivalent first-order Markov chain form is defined in Appendix.

As the epigenome evolves, the state associated with individual
positions may change. The types of changes we are most interested in
can be more naturally interpreted in terms of contiguous intervals. We
use the term epigenomic ``feature'' to refer to a consecutive interval
having the ``1'' state. The main types of changes we are interested in
are the following:
\begin{itemize}
\item {\it Birth and death:} During evolution, some new epigenomic
  feature may appear, or a feature that existed in an ancestor may
  disappear. %%% Should show examples
\item {\it Expansion and contraction:} As the epigenome evolves,
  epigenomic segments can become wider or more narrow, and this may
  happen in either direction.
\item {\it Merging and separating:} Two epigenomic features that are
  nearby in the ancestral genome may merge into a single interval.
  Conversely, a single epigenomic feature in the ancestral epigenome
  may separate into two intervals.
\end{itemize}
We will describe a model that treats the expansion and contraction of
features symmetrically in both directions along the genome.  This
choice in modeling is often reasonable, but not always. For example,
certain epigenomic modifications are frequently associated with parts
of genes (e.g. promoters), and the genes themselves have
directionality.
%%% Need to give examples where we believe this is reasonable, like
%%% enhancers that operate at a distance. But then cite CTCF
%%% directionality.

% The Gibbs measure is moved to here.
An epigenome is firstly modeled in graphical model that neighboring
sites are connected with undirected edges.  Let epigenome $s$ be the
sequence $s=s_1s_2\cdots s_N$ with $s_i$ denoting the state at
position $i$.
%An epigenome $s$ evolves over time, but we assume the
The stationary distribution for the epigenome has a Gibbs distribution
that factorizes over pairs of neighboring sites (see Appendix):
%% .  An equivalent
%% first-order Markov chain form is defined in Appendix.
\begin{equation}\label{eqn:stationary}
  \Pr(s) = \frac{1}{\mathcal{Z}}\exp\big\{\phi(s_1) +\sum_{n=1}^{N-1}\phi(s_n, s_{n+1}) + \phi(s_N)\big\},
\end{equation}
where $\mathcal{Z}$ is the partition function.

%%% Describe the paths for the full genome, and then the paths for
%%% individual sites
We are also interested in modeling sequences that evolve in continuous
time, and we use two representations to describe a particular
realization of the evolutionary process. These two representations
have distinct advantages, both in explaining aspects of our model and
in different computations.

Let $s$ be a sequence of $N$ binary states that evolve according to a
continuous time Markov process. The state space for $s$ has size
$2^N$, but we constrain instantaneous transition rates such that each
change to $s$ only involves a single site (coordinate) within $s$. We
can summarize the process as a {\it global path} over time interval
$\halfopen{0}{\tau}$ as follows:
\begin{equation}\label{globalJumps}
\begin{array}{llll}
H = (s, Y, V), ~\mbox{ where} & s \in \{0,1\}^N,\\
                              & Y = (y_1, \ldots, y_w), & \mbox{ with } 0 \leq y_i < y_{j} < \tau, & \mbox{ for } 1\leq i < j \leq w,\\
                              & V = (v_1,\ldots, v_w), & \mbox{ with } 1\leq v_i\leq N, & \mbox{ for } 1\leq i \leq w.
\end{array}
\end{equation}
Times $Y$ and positions $V$ are in direct correspondence, but we adopt
the notational convention $y_0 = 0$, allowing us to refer to any time
$y_{i-1}$, without any position corresponding to time $0$.
%%%
For any time $0 \leq t < \tau$, we let $s(t)$ denote the state
sequence after having applied changes to $s = s(0)$ at positions given
by $v_1,v_2,\ldots,v_k$ such that $y_k$ is maximal satisfying $y_k
\leq t$. From $H$ we can obtain $s(t)$ for any $0\leq t < \tau$ by
tracing changes made to $s$.
%%%

We can reorganize the same information to describe the process in
terms of {\it site-specific paths}. In particular, for site $1\leq n
\leq N$,
\begin{equation}\label{localJumps}
\begin{array}{llll}
H_n = (s_n, Y_n), ~\mbox{ where} & s_n \in \{0,1\},\\
                                 & Y_n = (y_1, \ldots, y_{w_n}),
                                 & \mbox{ with } 0\leq y_i < y_{j} < \tau,
                                 & \mbox{ for } 1\leq i < j \leq w_n.
\end{array}
\end{equation}
Our assumption that instantaneous rates are non-zero only for
transitions that modify a single position in $s$ defines bijection
between the global jump times $Y$ and the union of the site-specific
jump times $\cup_n Y_n$. Note that the sequences of site-specific
paths $(H_1,\ldots,H_N)$ more concisely describes a realization of our
process;
%%% JQU: Is the below statement too strong/general?
obtaining the state sequence $s(t)$ for any time $t$ requires
more effort.

%%% Introduce transition rates
The evolution of states at a given site in the state sequence $s$
depends on the states of its neighboring sites at all times during
evolution. Consider site $n$ and its two immediate neighbors $n-1$ and
$n+1$, and let the contemporaneous states for these sites at time $t$
be $s_{n-1}(t) = i$, $s_n(t)=j$ and $s_{n+1}(t)=j$. The instantaneous
rate for a transition at site $n$ from state $j$ to the complementary
binary state $\bar{j}$ is $\lambda(i, j, k)$. In other words, the
instantaneous rate $\lambda(i, j, k)$ is a function of the states at
the site of interest and its two immediate neighbors.  Since we assume
the evolutionary process is symmetric with respect to the direction
along the genome, we require $\lambda(i, j, k) = \lambda(k, j, i)$.

\subsection{Relating the substitution model and the stationary distribution}

\citetext{jensen2000probabilistic} gave a sufficient condition for a
continuous time evolutionary model with the properties we outlined for
$\lambda$ to have a stationary distribution of the form $\phi$. In
particular, if
%%% Prop 1 of J-P 2000
\begin{equation}\label{eqn:prop1}
  \frac{\lambda_{ijk}}{\lambda_{i\bar{j}k}} =
  \frac{\lambda(i, j, k)}{\lambda(i, \bar{j}, k)} =
  \frac{\exp(\phi(i, \bar{j})+ \phi(\bar{j}, k))}{\exp(\phi(i, j)+ \phi(j, k))},
\end{equation}
then \eqref{eqn:stationary} is the stationary distribution for the
Markov process with instantaneous rates $\lambda_{ijk}$.

\citetext{jensen2000probabilistic} also provide (Proposition 2) a way
of specifying $\lambda$ from $\phi$: substitution rates $\lambda$
satisfy the relation \eqref{eqn:prop1} if and only if they can be
written in the form
\begin{equation}\label{eqn:prop2}
  \log(\lambda_{ijk}) = -\psi(i, j, k) + \ell(i, k).
\end{equation}
This criteria was introduced in the context of an arbitrary number of
states for each position in the state sequence, and the $\ell$
function can be understood as $\ell(j, j'; i, k)$, for any two
different states $j$ and $j'$, which is symmetric in $(j, j')$. In our
setting the states are binary and $\ell$ is only a function of the two
neighboring states $(i,k)$. Moreover, we can directly verify that if
we define substitution rates as
\begin{equation}
  \log (\lambda_{ijk}) =  \ell(i, k) + (\phi(i, \bar{j}) +\phi(\bar{j}, k)),
\end{equation}
then they satisfy the condition of \eqref{eqn:prop2}.

\subsection{Parameterization and interpretation}

We can organize the neighbor-dependent transition rates of defined
above according to an $8\times8$ matrix:
\begin{equation}\label{eqn:Lambda}
  \renewcommand{\kbldelim}{(}% Left delimiter
  \renewcommand{\kbrdelim}{)}% Right delimiter
  \Lambda = \kbordermatrix{
    & 000 & 010 & 001 & 011 & 100 & 110 & 101 & 111 \\
    000 & \cdot & \mathcal{B} & 0 & 0 & 0 & 0 & 0 & 0 \\
    010 & \mathcal{D} & \cdot & 0 & 0 & 0 & 0 & 0 & 0 \\
    001 & 0 & 0 & \cdot & \mathcal{E} & 0 & 0 & 0 & 0 \\
    011 & 0 & 0 & \mathcal{C} & \cdot & 0 & 0 & 0 & 0 \\
    100 & 0 & 0 & 0 & 0 & \cdot & \mathcal{E} & 0 & 0 \\
    110 & 0 & 0 & 0 & 0 & \mathcal{C} & \cdot & 0 & 0 \\
    101 & 0 & 0 & 0 & 0 & 0 & 0 & \cdot & \mathcal{M} \\
    111 & 0 & 0 & 0 & 0 & 0 & 0 & \mathcal{S} & \cdot
  }
\end{equation}
We may interpret the non-zero entries in $\Lambda$ as corresponding to
biological events outlined in Section~\ref{biodefs}. The values
$\mathcal{B}$ and $\mathcal{D}$ are the rates of ``birth'' and
``death,'' respectively, for epigenomic features. The value
$\mathcal{M}$ corresponds to the merging of two features into a single
contiguous interval ($101\rightarrow 111$). Conversely, the value
$\mathcal{S}$ corresponds to epigenomic features ``splitting'' and
becoming two separate intervals ($111\rightarrow 101$). The remaining
non-zero values, $\mathcal{E}$ and $\mathcal{C}$, correspond to the
expansion (widening) and contraction (narrowing), of epigenomic
features. Both of these parameters appear twice in $\Lambda$,
reflecting our assumption that the rates governing any widening or
narrowing of intervals do not depend on direction, as explained in
Section~\ref{biodefs}.

If an epigenome evolves according to substitution rates $\Lambda$ with
stationary distribution \eqref{eqn:stationary}, then the condition in
\eqref{eqn:prop1} holds, and we have the following constraints for the
rates in the above matrix:
\begin{equation}\label{eqn:constraint}
  \mathcal{B}\mathcal{C}^2\mathcal{M}=\mathcal{D}\mathcal{E}^2\mathcal{S}.
\end{equation}
So given substitution rates $\birth{}, \death{}, \expansion{},
\contraction{}$, we have the following relationships between
horizontal potentials:
\begin{equation}\label{eqn:rel}
  \phi(0,0) = \phi(0,1) +\frac{1}{2}\log\left(\frac{\death{}}{\birth{}}\right), ~\text{ and }~
  \phi(1,1) = \phi(0,1) +\frac{1}{2}\log\left(\frac{\death{}\expansion{}^2}{\birth{}\contraction{}^2}\right).
\end{equation}

In summary, the transition rate matrix $\Lambda$ has 5 free
parameters; the two ratios $\death{}/\birth{}$ and
$\death{}\expansion{}^2/(\birth{}\contraction{}^2)$ uniquely
determine the stationary distribution \eqref{eqn:stationary} through
equation \eqref{eqn:rel}.
%%%
% If we add an additional constraint on the expected number of changes
% per unit time, then the model will have only 4 free parameters.

\section{Simulate epigenomic changes during evolution}

%%% ADS: do we need something in here to mention that we verified that
%%% simulation does work?

We model the evolution of the entire epigenome (as a sequence of
states) using a continuous time Markov process that only allows
instantaneous transitions from one sequence to another if the two
differ at a single position. The jumping rate at each position in the
epigenome is dependent on the state at that position and on the states
of the left and right neighboring positions. We assume for convenience
that the states of the first and last sites are fixed throughout
evolution.

Consider two epigenomes $s$ and $s'$ that differ by exactly one
position, and further suppose the state at that position in $x$ is
$j$, and $\bar{j}$ in epigenome $s'$. Neighboring positions in both
$s$ and $s'$ have states $i$ and $k$. The instantaneous rate of a jump
between $s$ and $s'$ is $\lambda_{ijk}$. These entries can be
organized as a transition matrix $R$ with $2^N\times 2^N$ entries, but
all positive values corresponding to some $\lambda_{ijk}$. The holding
time in a state sequence $s$ is exponentially distributed with rate
$-R_{ss}$ equal to the sum of instantaneous rates for jumps from $s$
to any state sequence $s'$ that differs from $s$ at exactly one
position. Expressed in terms of the triplet rates, for a state
sequence $s$ this parameter is
\[
-R_{ss} = \sum_{i,j,k}c_{ijk}(s)\lambda_{ijk},
\]
where $c_{ijk}(s) = \sum_{n=1}^{N-2}I(s_{n}=i, s_{n+1}=j, s_{n+2}=k)$
are the {\it ``triplet counts''} counting patterns $ijk$ in $s$.

Given that a jump has occurred at some fixed time, the probability
that the jump changed $s$ at the middle position of triplet $ijk$ is
proportional to $c_{ijk}(s)\lambda_{ijk}$. Further, given that a jump
occurred with context $ijk$, our model assumes the jump is equally
likely to have changed any position in $s$ having state $j$ with left
and right neighbors having states $i$ and $k$.
%%
When the process reaches equilibrium, the expected number of changes
per site per unit time is
%%% ADS: use of pi might not be consistent (root vs. stationary??)
$\sum_{ijk}\pi_{ijk}\lambda_{ijk}$, where $\pi_{ijk}$ is the
stationary distribution for the pattern $ijk$ in the epigenome.
%%% ADS: above, can we generalize away from epigenome here?
These assumptions suggest a simulation procedure, detailed in
Algorithm \ref{alg:simulation}. Note that
Algorithm~\ref{alg:simulation} requires an abstract data type that can
dynamically maintain specific information about the current global
state sequence $s$. In Appendix~\ref{} we present a data structure
that supports all required operations in constant time while requiring
only linear space.

\begin{algorithm}[t]
  \begin{algorithmic}[1]
    \caption{Simulating epigenome evolution}\label{alg:simulation}
    \REQUIRE Binary state sequence $s$ of length $N$, time $\tau$ and rates $\Lambda$.
    \ENSURE Simulated global path $H = (s, Y, V)$ for change times $Y$ and positions $V$.
    \STATE $t \gets 0$, $V\gets\emptyset$, $Y\gets\emptyset$, $x \gets s$
    \WHILE {$t < \tau$}
    \STATE Sample holding time $y\sim \mathit{Exp}(-R_{xx})$,
           where $-R_{xx} = \sum_{i,j,k}c_{ijk}(x)\lambda_{ijk}$
    \STATE $t \gets t + y$
    \IF {$t < \tau$}
    \STATE Sample binary triplet $ijk$ with probability proportional to $c_{ijk}(x)\lambda_{ijk}$
    \STATE Sample position $n$ uniformly from the $c_{ijk}(x)$ at center of a $ijk$ triplet in $x$
    \STATE Modify state sequence $x$ to have state $\bar{j}$ at position $n$
    \STATE Append $n$ to $V$ and append $t$ to $Y$
    \ENDIF
    \ENDWHILE
    \RETURN $H = (s, Y, V)$
  \end{algorithmic}
\end{algorithm}

%%% Implementation!!!

%%% plans for figures:
%%% multiple parameter settings (stationary, non-stationary, different rates)
%%% (1) distribution of patterns (stays stable, or moves towards target stationary state)
%%% (2) simulated paths with different parameter, show examples and summary statistics for events

%%% Liz: we need to clarify when and where the stationary condition is required.
%%% so that we don't need to resolve the confusion again when we talk about simulation
%%% and inference.

\section{Parameter estimation}

\subsection{Complete data}

First, given a global path $H$ for the evolution of an epigenome over
time $\halfopen{0}{\tau}$ with $\tau = 1$, we are interested in
estimating the transition rate parameters $\Lambda$.
%%% Liz: do we need to say \tau = 1 here?
%%% JQU: why assume stationary?
We assume a stationary process here, but this assumption is not
necessary (see Appendix).

Recall that for global path $H = (s, Y, V)$, the $m$-th jump occurs at
time $y_m$ and position $v_m$. Let $\context{m}$ denote the
\textit{context} of the $m$-th jump: the triplet $ijk$ of binary
states such that
\[
\context{m} = ijk ~~ \Rightarrow ~~ s_{v_m-1}(y_{m-1}) = i, ~ s_{v_m}(y_{m-1}) = j, ~ \mbox{ and } s_{v_m+1}(y_{m-1}) = k.
\]
So $\context{m}$ indicates the triplet that was modified by the $m$-th
jump. Note: $\context{m}$ is defined relative to a specific global
path $H$ that we leave implicit in our notation.

The holding time $\Delta_m = y_{m} - y_{m-1}$ just prior to the $m$-th
jump in the evolving state sequence follows the exponential
distribution
%%% ADS: need to relate $\lambda_m$ to $R_{xx}$
\[
\Delta_m \sim \mathit{Exp}(\lambda_m), ~\text{ with }~
\lambda_{m} = -R_{s(y_{m-1})s(y_{m-1})} = \sum_{i,j,k}c_{ijk}(s(y_{m-1}))\lambda_{ijk}.
\]
The likelihood function for parameters $\Lambda$ involves holding times and
identities of transitions:
\begin{equation}\label{eqn:lik}
  L(\Lambda | H) = \prod_{m=1}^{w} \lambda_{m} \exp(-\lambda_{m}\Delta_m)
  \times {\textstyle\left(\frac{\lambda_{\context{m}}}{\lambda_m}\right)}
  =\prod_{m=1}^{w}\lambda_{\context{m}}\exp(-\lambda_m\Delta_m).
\end{equation}
%%
And the log-likelihood function is
\begin{equation}\label{eqn:loglik}
  \begin{array}{ll}
    \log L(\Lambda | H) & = \sum_{i,j,k} \Big(\sum_{m=1}^w\log\lambda_{ijk}\times I{\{\context{m} = ijk\}} - c_{ijk}(s(y_{m-1}))\lambda_{ijk}\Delta_m\Big)\\[1em]
    & = \sum_{i,j,k} \left(J_{ijk}\log\lambda_{ijk} - D_{ijk}\lambda_{ijk} \right),
  \end{array}
\end{equation}
where
\begin{equation}\label{def:JD}
J_{ijk} = \sum_{m=1}^w I\{\context{m} = ijk\}
~~\mbox{ and }~~
D_{ijk} = \sum_{m=1}^w c_{ijk}(s(y_{m-1}))\Delta_m.
\end{equation}
Here $J_{ijk}$ counts jumps that create a triplet $ijk$ and $D_{ijk}$
measures the evolutionary time spent in context $ijk$, summed over all
sites in the state sequence (see Appendix for gradients used in
max-likelihood estimation).

%%%% Estimates when evolutionary time is a parameter

So far we have considered evolution along a single trajectory. In
general we are interested in evolution over a tree, and in this
setting the relative lengths of branches become important.  Let
$\mathcal{L} = \{\tau_1,\ldots,\tau_B\}$ denote the lengths of
branches in a tree with an assumed topology, with the additional
constraint that $\sum_{b=1}^B\tau_b = B$. With this view, the branch
lengths scale the transition rates. Let $H_b$ denote the global path
of jumps along branch $b$. Then the likelihood is a product over
likelihoods for the individual branches:
\begin{equation}\label{eqn:liknew}
  L(\Lambda, \mathcal{L} | \cup_{b} H(b)) = \prod_{b=1}^B L(\Lambda, \tau_b | H(b)) = \prod_{b=1}^B L(\tau_b \times \Lambda | H(b)),
\end{equation}
and
\begin{equation}\label{eqn:logliknew}
  \log L(\Lambda, \mathcal{L} | \cup_b H(b)) = \sum_{b=1}^B \log L(\Lambda, \mathcal{L} | \cup_b H(b)) = \sum_{b=1}^B \log L(\tau_b \times \Lambda | H(b)).
\end{equation}
%%% ADS: should we say something about the likelihood being the same
%%% if we partition the branches and histories into multi-branch
%%% paths: one from the root to a leaf, another from the root to
%%% another leaf, and then from internal nodes to leafs, etc.??
Compared with equations \eqref{eqn:loglik}, the terms on the left above
must be adjusted:
\begin{equation}\label{eqn:loglik1new}
  \log L(\tau_b \times \Lambda | H(b)) = \sum_{i,j,k} J(b)_{ijk}\log(\tau_b\lambda_{ijk}) - D(b)_{ijk}\times(\tau_b\lambda_{ijk}),
\end{equation}
with $J(b)$ and $D(b)$ defined by equation~\eqref{def:JD} but
specifically in terms of global path $H(b)$ for branch $b$.

%% interval $\Delta_{bm}$ on branch $b$ observed when the branch length
%% is $\ell_b$, the scaled interval length is $\Delta_{bm}\times
%% \frac{\ell'_b}{\ell_b}$ under the new branch length. Therefore, under
%% the new model parameter set $\{\ell'_b\}$ and $\{\lambda'_c\}$, we
%% have
%% \[
%% \Delta_{mb}\times \frac{\ell'_b}{\ell_b} \sim \mathit{Exp}(\lambda'_{(bm)}) \Rightarrow
%% \Delta_{mb} \sim \mathit{Exp}(\lambda'_{(bm)} \times \frac{\ell'_b}{\ell_b}).
%% \]
%% %%%%%
%% Let $\tau_b = \frac{\ell'_b}{\ell_b}$ be the scaling factor for the
%% new branch lengths relative to the old branch lengths. Now we can
%% write the likelihood of observing all of the given jumping intervals
%% $\{\Delta_{b,m}\}$ under the new parameter set as :
%% \begin{equation}\label{eqn:liknew}
%%   \begin{aligned}
%%     L(\{\Delta_{b,m}\}; \{\ell'_b\}, \{\lambda'_c\})
%%     = & \prod\limits_{b=1}^B\Bigg(\prod\limits_{m=1}^{M_b-1}
%%     \lambda'_{(b,m)}\tau_b
%%     \exp(-\lambda'_{(b,m)}\tau_b\Delta_m) \times \frac{\lambda'_{\context{}_m}}{\lambda'_{(m)}}
%%     \Bigg) \times \exp(-\lambda'_{(b,M_b)}\tau_b\Delta_{M_b})\\
%%     = & \prod\limits_{b=1}^B\Bigg(
%%     \prod\limits_{m=1}^{M_b-1}\lambda'_{\context{}_m}\tau_b\exp(-\lambda'_{(m)}\tau_b\Delta_m)
%%     \Bigg)\times \exp(-\lambda'_{(b,M_b)}\tau_b\Delta_{M_b}).
%%   \end{aligned}
%% \end{equation}
%% %%%%%
%% The log likelihood becomes
%% \begin{equation}\label{eqn:logliknew}
%%   \begin{aligned}
%%     l = & \sum\limits_{b=1}^B\sum\limits_{m=1}^{M_b-1} \log(\lambda'_{c_m}\tau_b) -  \sum\limits_{b=1}^B\sum\limits_{m=1}^{M} \lambda'_{(m)}\Delta_{bm}\tau_b \\
%%     = & \sum\limits_{b=1}^B\sum_{c} J_{bc}\log(\lambda'_c\tau_b)  - \sum\limits_{b=1}^B\sum_{c} D_{b,c}\lambda'_c\tau_b ,
%%   \end{aligned}
%% \end{equation}
%% where $J_{b,c} = \sum\limits_{m=1}^{M_b-1}I_{\{c_{b,m}= c\}}$, $D_{bc}
%% = \sum\limits_{m=1}^{M_b}I_{\{c_{b,m} =c\}}\Delta_{b,m}$, $c_{b,m}$ is
%% the context of the $m$-th jump on branch $b$, and $\Delta_{bm}$ is the
%% holding time before the $m$-th jump on branch $b$ of length
%% $\ell_b$. Then, we can optimize \eqref{eqn:logliknew} over
%% $\{\tau_b\}$ and $\{\lambda'_c\}$, and set new branch lengths
%% $\{\ell'_b = \tau_b\ell_b\}$.


\subsection{Inference from incomplete data}
%%% Liz: "Inference from incomplete data on single branch?"
In applications we have data, in the form of epigenomic state
sequences, associated with leaf nodes. Even at leaf nodes our data may
be incomplete. We do not have data corresponding to internal nodes,
let alone the full paths of jumps and corresponding positions in
continuous time. In addition to estimating model parameters from such
incomplete data, we can learn much from estimating state sequences at
internal tree nodes.

The method we use follows that outlined by
\citetext{jensen2000probabilistic} and \citetext{hobolth2008markov}.
The basic machinery we borrow is most easily explained by first
focusing on a single trajectory (single branch tree) with known
site-specific paths for all sites except $n$. We can sample a path
$H_n'$ according to the distribution
\[
\Pr(H_n' | H_1, \ldots, H_{n-1}, H_{n+1},\ldots, H_N) = \Pr(H_n' | H_{\overline{n}})
\]
by using MCMC and the likelihood from equation~\eqref{eqn:lik}. When $H_n'$ is
known partially, for example if the starting state $s_n(0)$ and the
ending state $s_n(1)$ are known, MCMC can be applied similarly to
sample a path consistent with those end-points. If the data are state
sequences at leaf nodes of a tree having known topology, the approach
of \citetext{hobolth2008markov} can be used to sample site-specific
paths for all sites and all branches in the tree. Summarizing these
samples provides estimates of expected states at all sites for all
ancestral nodes. Importantly, such estimates made by sampling
site-specific paths are consistent with our distributional assumptions
for the global state space. Although this general strategy allows much
flexibility, efficient sampling is still a major challenge.

%%% ADS: need summary of work here on end-point conditioned path
%%% sampling

\section{Inferences in the context of a tree structure with fixed leaf data}

Now we assume the epigenome has evolved according to a tree structure,
and we wish to make inferences about a bifurcating evolutionary
process. The paths associated with a given site must satisfy
additional constraints to be ``consistent.'' We first consider a tree
with 3 nodes, a root $u$ with a single child node $v$ and two leaf
nodes below $v$, denoted $w_1$ and $w_2$. The branches of the tree are
$(u, v)$, $(v, w_1)$ and $(v, w_2)$. We assume we are given the
epigenome at each node in this tree, with the exception of the state
at position $n$ of node $v$. We are also given all paths for sites
other than site $n$. We want to make inferences about the state at
position $n$ of $v$, and also about the paths for edges incident on
$v(n)$. We require a method for sampling paths at site $n$ that share
a common state at their common end-point.
%%%
\citetext{hobolth2009simulation} reviewed and compared three
approaches to sample paths of discrete-state continuous-time Markov
chain conditional on end-point states, namely the rejection sampling,
direct sampling and uniformization. We use the direct sampling method
for the end-conditioned sampling of a ctMC path, as detailed by
\citetext{hobolth2008markov} and below.
%%
% Method 1 in the previous section
% is similar to uniformization, since the neighboring sites may have
% state changes, and the rate of jumps depends on the contemporary
% states of the neighboring sites. We proposed to use an averaged rate
% to for the Poisson distribution, and let the acceptance probability to
% do most of the work of correcting the proposal distribution towards
% the posterior distribution. Method 2 is forward sampling, which is the
% basis of rejection sampling.

%% \paragraph{Rejection sampling for the proposal:}
%% This approach first does forward sampling as described in Method 2
%% above for position $n$ along the branch $(u,v)$ and $(v, w_1)$, which
%% can be viewed as a single path that proceeds along two consecutive
%% edges. The sampled path provides a state $x$ corresponding to node
%% $v$.  Next, a path is sampled for edge $(v, w_2)$ assuming state $x$
%% at node $v$. If this path finishes with the known state at position
%% $n$ in $w_2$, we retain the 3 paths $L_{n}^{(u,v)}$, $L_{n}^{(v,w_1)}$
%% and $L_{n}^{(v,w_2)}$ as a proposal. The proposal is evaluated using
%% the same acceptance rule given above in equation
%% \eqref{eqn:rejection}.

%% %% Reject the path
%% %% unless the end state agree with the given state at node $a$ at
%% %% position $n$.  Then do forward sampling along the branch $(v, b)$,
%% %% with the accepted simulated state of node $v$. If the end state does
%% %% not agree with the given state at node $b$ at position $n$, start over
%% %% the sampling from the beginning, \textit{i.e.} start over from node
%% %% $u$. Because we are not taking site $n-2$ and $n+2$ into
%% %% consideration, we are not directly sampling from the posterior
%% %% distribution of the paths, therefore the rejection sampling procedure
%% %% is a way to propose viable paths, then we use the MCMC acceptance rule
%% %% \eqref{eqn:rejection} to reshape the proposal distribution to the
%% %% posterior distribution.

%% A couple of performance statistics should be measured for this
%% proposed sampling method. These include (1) the success rate for
%% generating valid paths that satisfy the end conditions; (2) the
%% acceptance rate of proposed valid paths in MCMC sampling.

\subsection{Posterior sampling of a path on the entire phylogenetic tree}

For a phylogenetic tree with known branch lengths and known
evolutionary context-dependent transition rates, how can we sample the
evolutionary path (on the entire tree) for one site from its posterior
distribution given observed evolutionary paths at all other sites and the
observed states at all leaf nodes for this site?

\paragraph{Tree branch partitions imposed by states at neighboring sites.}
The evolutionary process at an individual site is not homogeneous
along a branch, as its transition rates depend on states of
neighboring sites at any instant. At a given site $n$, we partition
each branch into maximal contiguous intervals such that the states at
neighboring sites are unchanged during those intervals. For site $n$,
define homogeneous break times $Z_{n,b} = (z_0,z_1,\ldots,z_{w_{n-1} +
  w_{n+1}}, \tau_b)$, or $h$-breaks, as the ordered set of times from
$Y_{n-1}$ and $Y_{n+1}$, with $z_0 = 0$. For $0 < i \leq |Z_{n,b}|$,
during each time interval $(z_{i-1}, z_{i})$ the state at site $n-1$
and site $n+1$ remains unchanged along branch $b$. We denote these
time intervals as $h$-intervals, along which the evolutionary process
can be treated as homogeneous.
%%%
For each branch $b$ in the tree, we can use the set of $h$-breaks
$Z_{n,b}$ to define a new set of nodes between $u$ and $v$, such that
each new node only has one child. This will allow us to simplify the
problem of sampling continuous time jump paths for an individual site.

%%% ADS: need to define P and Q here...
{\bf need to fix this paragraph to define P and Q properly.}

The evolutionary process at site $n$ within the $m\tth{}$ $h$-interval
on branch $b$ is thus a time-homogeneous continuous-time Markov chain
with transition rate matrix $Q_{bm}$ defined by the states at
neighboring sites. The states of this site of interest at the start
and the end of an $h$-interval, $s_{b,m-1}$ and $s_{b,m}$, are
connected through a transition probability matrix $P_{b,m} =
\exp(Q_{bm}t_{bm})$.  The likelihood of observing leaf node states at
this site $\{s_n(v)\}$, given the evolutionary paths at other sites is
\[
\Pr(\{s_n(v)\} | H_{\overline{n}}) = \sum_{\{s_{bm}\}} \prod_{b} \prod_{m} P_{bm}(s_{b,m-1}, s_{b, m})
\]
%%% ADS: need to define $X$ such that it is a data structure that
%%% associates states with a subset of nodes, and indicates which
%%% nodes have assigned states
We use Felsenstein's pruning algorithm to compute this
probability. Let the phylogenetic tree be $G_n$ consisting of all leaf
nodes and internal nodes from $G$, and all breakpoint nodes at times
$Z_n(b)$ on each branch $b$ of $G$. For any node $u\in G_n$ let
$X_n(u)$ be the states of all leaf nodes below $u$ at site $n$
(Figure~\ref{fig:treebreak}). The state transition probabilities from
the parent of node $u$ to node $u$ are
\[
P_u = \exp(Q_{\context{u}}\tau_u).
\]
We use the following notation to describe the algorithm:
%%% ADS: does X_n(v) include v if v is a leaf?
\begin{equation}\label{def:pandq}
\begin{array}{lll}
p_j(v) = \Pr(X_n(v) | s_n(u) = j), & \begin{array}{l}\mbox{where $u$ is the parent of $v$,}\end{array}\\[1em]
q_j(u) = \left\{
\begin{array}{l}
  \Pr(s_n(u) = j),\\
  \prod_{v\in \child{u}} p_{j}(v),
\end{array}\right.&%%
\begin{array}{l}
  \mbox{if $u$ is a leaf node},\\
  \mbox{otherwise}.
\end{array}
\end{array}
\end{equation}
If the state $s_n(u)$ is observed ({\it i.e.} at a leaf) then
$\Pr(s_n(u) = j) \in \{0, 1\}$. If the data are continuous or given as
expected states or posterior probabilities, then $\Pr(s_n(u) = j) \in
(0, 1)$.
%%% ADS: above, not sure about generality needed???
In the bottom-up pass of Felsenstein's pruning algorithm we compute
\begin{equation}
  p_j(u) = {\textstyle \sum_{k}} P_u(j, k) \times q_{k}(u).
\end{equation}
In this way, we can compute the marginal posterior probability of
observing the states $X_n(r)$ at all leaf nodes below the
root node $r$ at site $n$,
given the evolutionary paths at all other sites:
\begin{equation}\label{eqn:leafmarginal}
  \Pr(X_n(r) | H_{\overline{n}}) = \sum_j\Pr(s_n(r) = j | H_{\overline{n}}) q_j(r).
\end{equation}
%%%
The marginal posterior distribution of the root node's state is
\begin{equation} \label{eqn:rootposterior}
  \begin{aligned}
    \Pr(s_n(r)| H_{\overline{n}}, X_n(r)) = &
    \frac{\Pr(s_n(r), X_n(r) | H_{\overline{n}})}{\Pr(X_n(r) | H_{\overline{n}})} =
    \frac{\Pr(X_n(r) |s_n(r), H_{\overline{n}}) \Pr(s_n(r) | H_{\overline{n}})}{\Pr(X_n(r)| H_{\overline{n}}) }  \\
= & \frac{\Pr(s_n(r)|H_{\overline{n}}) \prod_{v\in \child{r}} p_{s_n(r)}(v)}{\Pr(X_n(r)| H_{\overline{n}}) },
\end{aligned}
\end{equation}
where $\Pr(s_n(r)|H_{\overline{n}})$ is the initial distribution of the root node
state given its sequence context, which we can compute from the
stationary distribution of the root epigenomic sequence characterized
by either a Gibbs measure, or a Markov chain.

In summary, during the bottom-up Pruning algorithm \ref{alg:bottomup},
we compute $p_j(v), q_k(v)$, and ultimately the marginal probabilities
$\Pr(X_n(r) | H_{\overline{n}})$ and $\Pr(s_n(r)|H_{\overline{n}},
X_n(r))$.

\paragraph{Top-down posterior sampling at breakpoints.}
Let $S$ be the states at all internal nodes. The posterior probability
of all internal nodes taking the states $S$, given the leaf node
states $X_n(r)$ and the evolutionary paths at all other sites, is
\[
\Pr(S | X_n(r), H_{\overline{n}}) = \frac{\Pr(S, X_n(r) | H_{\overline{n}}) }{\Pr(X_n(r) | H_{\overline{n}})},
\]
where $\Pr(S, X_n(r) | H_{\overline{n}}) $ is the forward sampling probability
under the given transition probability matrices in individual
intervals determined by $H_{\overline{n}}$.
Therefore, we can do exact posterior sampling of the joint states at
the break points between the intervals on the phylogenetic tree through
direct sampling following Algorithm~\ref{alg:topdown}.

%%%%%%
%%%%%%
\paragraph{Direct sampling of path between breakpoints with fixed states.}
Next, we sample the state transitions at this position within each
single time interval, during which its two neighbors have unchanged
states, and the initial and final states for this time interval are
fixed.  Focusing on one interval, let $0$ and $\tau$ be the end time
points.  Let an instance of the path within this interval be $h_n=
\{t_m\}_{m=0}^{M}$, which is a set of jumping times and the start and
end time points ($t_0 = 0$ and $t_M=\tau$). Let $\Delta_m = t_m -
t_{m-1}$ be the holding time between jumps. Let the homogeneous
transition rate matrix be $Q$ for this site in this time interval, and
$P(t)$ be the transition probability matrix for states at two time
points separated by time $t$. We use the direct sampling procedure
\cite{hobolth2009simulation} for endpoint-conditioned path sampling.

If the endpoints have the same state $i$, the probability that there
are no change during this time interval is
\begin{equation} \label{eqn:pnojump}
p_i = \frac{\exp(Q_{ii}\tau)}{P(\tau)_{ii}}.
\end{equation}
Then with probability $1-p_i$, at least one (actually two) state change occurs.

Let $W$ be the waiting time until the first jump.
\begin{equation}
\begin{aligned}
& \Pr(W < \tau | s(0) = i, s(\tau) = j)  \\
& =  \Pr(W < \tau, s(W) = \bar{i} | s(0) = i, s(\tau) = j)\\
& = \frac{\Pr(W < \tau, s(W) = \bar{i},s(\tau) = j | s(0) = i) } {\Pr(s(\tau) = j | s(0) = i)}  \\
& = \int_{0}^{\tau} Q_{i\bar{i}} \exp(Q_{ii}w) \frac{P(\tau-w)_{\bar{i}j}}{P(\tau)_{ij}} dw \\
& = \int_{0}^{\tau} f_{ij\tau}(w) dw, \text{~where~}
f_{ij\tau}(t) = Q_{i\bar{i}} \exp(Q_{ii}t) \frac{P(\tau-t)_{\bar{i}j}}{P(\tau)_{ij}}.
\end{aligned}
\end{equation}
The direct sampling procedure for a homogeneous continuous-time Markov
path within an end-conditioned interval is detailed in
Algorithm~\ref{alg:samplepath}.

The acceptance probability of the end-conditioned sampling result
$H_n'$, an evolutionary path over the entire tree at site $n$, can be
computed as
\begin{equation}\label{def:accept}
  \alpha = \min\left\{\frac{\pi(H_n', H_{\overline{n}})/g(H_n')}{\pi(H_n, H_{\overline{n}})/g(H_n)}, 1\right\},
\end{equation}
where $H_n$ is the current path state, $\pi$ is the complete data
likelihood function \eqref{eqn:lik} and $g$ is the proposal
probability density function for the direct end-conditioned sampling
of a ctMC path that generated $H_n'$.  For two versions of complete
evolutionary history that only differ at one position, their
likelihood ratio is determined by the paths at that position, and two
positions to each side, \textit{i.e.} 5 positions in total. Because
the total time spent in each triplet context \eqref{def:JD} is altered
at the center position and its two neighboring positions.

\section{Discussion}

As noted earlier, the generalizations previously described for
phylo-HMMs have many similarities with the model we proposed. In
particular, these generalizations associate a binary variable with
each nucleotide in each sequence, including ancestral sequences.  The
most notable difference is our emphasis on interpretability of the
horizontal relationships, specifically that an individual epigenome
(extant or ancestral) follows a Markov process. Another difference is
our adoption of a homogeneous continuous time process, which is both
built into the model, and exploited by our inference
procedure. Phylogenetic HMMs are applied to determine states along
aligned genomes where those genome sequence evolve according to a
particular substitution model. Our notion of the epigenome corresponds
more closely to the idea of ``conserved'' and ``non-conserved''
states, but the details of our approaches are more similar to the
substitution process of nucleotides, rather than general
time-dependent graphical models.

\clearpage

\bibliographystyle{namedplus}
\bibliography{biblio}

\clearpage

\appendix

\section{Relating the Gibbs measure potentials and Markov chain probabilities}

%%% Gibbs to MC
The stationary distribution in \eqref{eqn:stationary} is equivalent to
the distribution of a Markov chain. Therefore, when the epigenome is
modeled with a Gibbs measure, we can sample an instance of the state
sequence, or evaluate its probability, using the equivalent Markov
chain. We can relate the factors in \eqref{eqn:stationary} and the
transition probabilities of the Markov chain as follows. Define
pair-wise potentials $\Psi(i,j)=\exp(\phi(i, j))$, where $i, j\in\{0,1\}$
are binary states. The largest eigenvalue of $\Psi$ is
\[
q=\textstyle\frac{1}{2}\left(\Psi(0,0)+\Psi(1,1) +\sqrt{\Delta}\right), \text{ where }
\Delta=(\Psi(0,0) - \Psi(1,1))^2 + 4\Psi(0,1)\Psi(1,0).
\]
Let $h$ be a right eigenvector of $Q$ corresponding to $q$, then we have
\[
\frac{h_0}{h_1} = \frac{\Psi(0,1)}{q-\Psi(0,0)} = \frac{q-\Psi(1,1)}{\Psi(1,0)}.
\]
The Markov chain transition matrix is:
\[
T(i,j) = \frac{\Psi(i,j)h_j}{qh_{i}},~\text{where } i,j \in\{0,1\}.
\]
More specifically,
\begin{equation} \label{eqn:gibbs2markov}
  \begin{array}{ll}
    T(1,1) = \displaystyle\frac{2\Psi(1,1)}{\Psi(0,0)+\Psi(1,1)+\sqrt{\Delta}}, &
    T(0,0) = \displaystyle\frac{2\Psi(0,0)}{\Psi(0,0)+\Psi(1,1)+\sqrt{\Delta}}, \\[2em]
    T(0,1) = \displaystyle\frac{4\Psi(0,1)\Psi(1,0)}{(\Psi(0,0)+\sqrt{\Delta})^2 -\Psi(1,1)^2}, &
    T(1,0) = \displaystyle\frac{4\Psi(0,1)\Psi(1,0)}{(\Psi(1,1)+\sqrt{\Delta})^2 -\Psi(0,0)^2}.
  \end{array}
\end{equation}
Accordingly, the expected fraction of an epigenome state sequence
residing within functional domains (the ``features'') is:
\[
1- \frac{2\Psi(0,1)\Psi(1,0)}{(\Psi(0,0)-\Psi(1,1))^2 + 4\Psi(0,1)\Psi(1,0) +
  (\Psi(1,1)-\Psi(0,0))\sqrt{\Delta}}.
\]


%%% MC to Gibbs
Converting a Markov chain to an equivalent Gibbs measure is more
straight forward. Given Markov chain transition probability matrix
$T$, we can choose potentials $\Psi(i,j) = \exp(\phi(i,j))$ as
\[
\Psi =
 \begin{bmatrix}
   1 - T(0,1) & \sqrt{T(0,1)T(1,0)} \\
    \sqrt{T(0,1)T(1,0)} & 1-T(1,0)
 \end{bmatrix}
\]

\section{Equations for maximum likelihood estimation}

If we do not assume a stationary process, we may also be interested in
the properties of the epigenome at time 0, which are characterized by
the Markov chain transition
%%% ADS: not sure if we want to work directly with $T$ below
probabilities $T_{0}$. These transition probabilities are easy to
infer given the complete observations at the time-0 epigenome.  Define
{\it pair counts} $c_{ij} = \sum_{n=1}^{N-1}I\{s_n(0) =i,
s_{n+1}(0)=j\}$ with analogy to the triplet counts defined above. Then
\[
\hat{T}_{00} = \frac{c_{00}}{\sum_{n=1}^{N-1}I\{s_n(0) = 0\}}, ~
\hat{T}_{11} = \frac{c_{11}}{\sum_{n=1}^{N-1}I\{s_n(0) = 1\}}.
\]

The constraints on the transition rates $\lambda_{ijk}$ as indicated
in the matrix \eqref{eqn:Lambda} and equation \eqref{eqn:constraint}
are:
\begin{equation}\label{eqn:constraints}
  %% \left\{
  \begin{array}{c}
    \lambda_{001} = \lambda_{100}\\
    \lambda_{011} = \lambda_{110}\\
    \lambda_{000}\lambda_{110}^2\lambda_{101} = \lambda_{010}\lambda_{100}^2\lambda_{111}
  \end{array}
  %% \right.
\end{equation}
So for the purpose of estimating parameters, we only require 5
gradients.

We treat $\{\log\lambda_c: c = 0,1,2,3,5\}$ as free parameters as they
can take any real value.
\begin{equation}
  \begin{aligned}
    \frac{\partial l}{\partial \log\lambda_0} &= J_0 - D_0\lambda_0 + J_7 - D_7\lambda_7\\
    \frac{\partial l}{\partial \log\lambda_2} &= J_2 - D_2\lambda_2 - J_7 + D_7\lambda_7 \\
    \frac{\partial l}{\partial \log\lambda_5} &= J_5 - D_5\lambda_5 + J_7 - D_7\lambda_7\\
    \frac{\partial l}{\partial \log\lambda_1} &= J_1 + J_4 - (D_1 + D_4)\lambda_1 - 2J_7 + 2D_7\lambda_7\\
    \frac{\partial l}{\partial \log\lambda_3} &= J_3 + J_6 - (D_3 + D_6)\lambda_3 + 2J_7 - 2D_7\lambda_7
  \end{aligned}
\end{equation}


%%% below serves as a reference for our code
%%% may be masked in the appendix
\section{End-conditioned path sampling for continuous-time Markov chain}

We used the exact path sampling algorithm of \citetext{hobolth2008markov}.
The $2\times2$ transition rate matrix $Q$ has an eigenvalue decomposition $Q = UDU^{-1}$,
where $D$ is the diagonal matrix of eigenvalues and $U$ is a matrix of orthogonal eigenvectors.
%
\[
Q =
 \begin{bmatrix}
  -\lambda_0 & \lambda_0 \\
  \lambda_1 & -\lambda_1
 \end{bmatrix}, ~~
D =
 \begin{bmatrix}
  0 & 0 \\
  0 & -\lambda_0-\lambda_1
 \end{bmatrix}, ~~
U =
 \begin{bmatrix}
  1 & \lambda_0 \\
  1 & -\lambda_1
 \end{bmatrix},  ~~\text{and}~~
 U^{-1} = \frac{1}{\lambda_0+\lambda_1}
 \begin{bmatrix}
  \lambda_1 & \lambda_0 \\
  1 & -1
 \end{bmatrix}.
\]
%
The transition probability matrix between two time points separated by time $t$ is
\begin{equation}
P(t) = e^{Qt} = Ue^{tD}U^{-1} = \frac{1}{\lambda_0+\lambda_1} \begin{bmatrix}
  \lambda_0 h(t) + \lambda_1 & \lambda_0 (1-h(t)) \\
  \lambda_1(1-h(t)) & \lambda_0 + \lambda_1 h(t)
 \end{bmatrix},
\end{equation}
where $h(t) = exp(-(\lambda_0 + \lambda_1)t)$.

First consider the case where the states of the two end points of a time interval
$T$ are identical, \text{i.e.} $X(0) = X(T) = a$, the probability that
there are no state changes in the time interval $[0,T]$ is
\begin{equation}
p_a = \frac{exp(-\lambda_aT)}{P(T)_{aa}}.
\end{equation}

Next consider the case where $X(0) = a$, $X(T) = b$, and at least one
change occurs within the time interval. The conditional probability
that the first state change from $a$ to $\bar{a}$ happens at a time
smaller than $t$ is
\begin{equation}
\begin{aligned}
&\Pr(\tau \le t, X(\tau) = \bar{a} | X(0) = a, X(T) = b) \\
&= \Pr(\tau \le t, X(\tau) = \bar{a}, X(T) = b| X(0) = a) / \Pr(X(T) = b | X(0) = a) \\
&= \int_{0}^{t} \lambda_ae^{-\lambda_a\tau}P(T-\tau)_{\bar{a}b}/ P(T)_{ab} ~ d\tau \\
&= \int_{0}^{t}\frac{\lambda_a}{P(T)_{ab}}\sum\limits_{i} U_{\bar{a}i}U_{ib}^{-1} e^{TD_i}e^{-\tau(\lambda_a+D_i)} \\
& = \int_{0}^{t} f_{abT}(\tau) ~d\tau,
\end{aligned}
\end{equation}


\clearpage

\section{Algorithms used for sampling at individual sites}

\begin{algorithm}[h!]
  \begin{algorithmic}[1]
    \caption{Pruning$(u, X_n(u))$}\label{alg:bottomup}
    \REQUIRE Phylogenetic tree $u$ with associated transition probabilities
    \ENSURE Values $p_j(u)$ and $q_j(u)$ for $j\in \{0, 1\}$ as defined in equation~\eqref{def:pandq}
    \STATE $q_j(u) \gets 1$ iff state $s_n(u) = j$ is compatible with $X_n(u)$, for $j\in \{0,1\}$
    %% I\{s_n(u) = j\}$ for $j\in \{0,1\}$ %% \Pr(s_n(u) = j)$ for $j \in \{0,1\}$
    \FOR {child $v$ of $u$}
    \STATE $\{p_j(v), q_j(v)\} \gets$ Pruning$(v, X_n(v))$
    \STATE $q_j(u) \gets q_j(u) \times p_{j}(v)$ for $j\in \{0,1\}$
    \ENDFOR
    \STATE $p_j(u) \gets \sum_{k\in\{0,1\}} P_u(j, k) \times q_k(u)$ for $j\in\{0,1\}$
    \RETURN $p_j(u)$ and $q_j(u)$ for $j\in\{0,1\}$
  \end{algorithmic}
\end{algorithm}

%% \begin{algorithm}[t]
%%   \begin{algorithmic}[1]
%%     \caption{Pruning algorithm with observed leaf states $X_n(r)$}\label{alg:bottomup}
%%     \FOR {node $v$ in post-order traversal}
%%     \IF {$v\neq r$}
%%     \IF {$v$ is a leaf node}
%%     \STATE $q_k(v) \gets \Pr(s_v = k)$ for $k \in \{0,1\}$.
%%     \ELSE
%%     \STATE $q_k(v) \gets \prod_{u\in \child{v}} p_{k}(u)$
%%     \ENDIF
%%     \STATE $p_j(v) \gets \sum_{k} P_v(j,k) \times q_k(v)$, for $j = 0, 1$.
%%     \ELSE
%%     \STATE Compute $\Pr(X_n(r) | H_{\overline{n}})$ as in
%%     \eqref{eqn:leafmarginal}, and $\Pr(s_n(r)| H_{\overline{n}}, X_n(r))$ as in
%%     \eqref{eqn:rootposterior}
%%     \ENDIF
%%     \ENDFOR
%%   \end{algorithmic}
%% \end{algorithm}

\begin{algorithm}[h!]
  \begin{algorithmic}[1]
    \caption{DownwardStateSampling$(u, s(u), X(u))$}\label{alg:topdown}
%%%
    \REQUIRE Phylogenetic tree node $u$, binary state $s(u)$ and
    states $X(u)$ for all leaves below $u$
%%%
    \ENSURE Sampled states for all internal nodes $v$ in the tree
    rooted at $u$
%%%
    \FOR {each child node $v$ of $u$}
    %% \STATE Sample state $s_n(v)$ conditional on $H_{\overline{n}}$ and $X_n(u)$
    %% according to \eqref{eqn:rootposterior}.
    \STATE Sample $s(v) \sim P(s(v)=k|X(u), s(u)=j) = P_v(j, k) \times q_k(v)\slash p_j(v)$
    %% \[k \sim \frac{1}{p_j(v)}\times P_v[j,k] \times q_k(v) \]
    \STATE Update the direct sampling probability with factor $P_v(j,k)q_k(v)\slash p_j(v)$
    \STATE DownwardStateSampling$(v, s(v), X(v))$
    \ENDFOR
    \STATE The result is an sample $S$ of states at all internal states,
    which is sampled from their joint marginal posterior probability
    distribution $\Pr(S| X_n(r), H_{\overline{n}}) $.
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
  \begin{algorithmic}[1]
    \caption{DirectEndConditionedPathSampling$()$}\label{alg:samplepath}
%%%
    \REQUIRE a
%%%
    \ENSURE b
    \STATE Suppose interval has length $\tau$, and start and end states $i, j$:
    \WHILE {$\tau > 0$}
    \IF {$i = j$}
    \STATE Sample $Z\sim \text{Bernoulli}(p_i)$, where
    $p_i$ is given in \eqref{eqn:pnojump}.
    \IF {$Z = 1$}
    \STATE Set $s(t) = i$ for all $0 < t < \tau$, and update $\tau \gets 0$.
    \ENDIF
    \ENDIF
    \IF {$i \neq j$ or $Z = 0$}
    \STATE Sample the waiting time $W$ in state $i$ according to the continuous
    density $f_{ij\tau}(w)$, $0< w < \tau$, set $s(t) = i$ for $0 < t < W$
    \STATE Update $i \gets \bar{i}$, $\tau \gets \tau - W$.
    \ENDIF
    \ENDWHILE
  \end{algorithmic}
\end{algorithm}

\appendix

\section{Data structuring}
\label{sec:datastruct}

We say the site at position $n$ in a state sequence $x$ matches a
triplet pattern $ijk\in\{0,1\}^3$ iff $(x_{n-1},x_n,x_{n+1})=(i,j,k)$.
For convenience in our explanation below, we may use the binary
triplet $ijk$ interchangeably with its numerical representation:
integer values in $[0,8)$. The latter interpretation will help when a
binary tripet is used as an index into an array.

Algorithm~\ref{alg:simulation} assumes an abstract data type defined
by the following operations:
\begin{enumerate}
\item Triplet count retrieval: given a state sequence $x$ and a binary
  triplet $ijk$, return the number $c_{ijk}(x)$ of sites in $x$
  matching the triplet pattern $ijk$. We denote this operation simply
  by $c_{ijk}(x)$.
\item Triplet site sampling: given a state $x$ and a binary triplet
  $ijk$, return a position $n$ sampled uniformly at random from the
  set of positions matching triplet pattern $ijk$. We denote this
  operation by $\mathit{sample}(x, ijk)$.
\end{enumerate}
For static $x$, a table of 8 values suffices for $c_{ijk}(x)$ in
constant time, and 8 sets suffice for $\mathit{sample}(x, ijk)$ in
constant time, each requiring linear time
pre-processing. Algorithm~\ref{alg:simulation} requires supporting
$c_{ijk}(x)$ and $\mathit{sample}(x, ijk)$ as $x$ changes by
complementing the state at random positions. Reconstructing simple
tables is too costly. Modifying existing structures requires not only
considering the change to triplet pattern centered on position $n$ but
also those centered on $n-1$ and $n+1$, as their last and first bits,
respectively, are complemented. So we must also take into account
updates to information about $x_{n-1}$ and $x_{n+1}$. Changing up to 6
values in a table storing $c_{ijk}(x)$ poses no problem, but the
necessary updates that would be required to support
$\mathit{sample}(x, ijk)$ if positions corresponding to each triple
are explicitly stored as sets requires those data structures have
dynamic sizes.

Clearly the state sequence $x$ itself supports the two required
operations: triplet count retrieval can be accomplished by a linear
scan of $x$, as can triplet site sampling, neither changing the size
of $x$, the underlying data structure. However, in the context of
Algorithm~\ref{alg:simulation}, linear time operations would
drastically restrict the simulation time interval and the size of
state sequences that can be simulated.

We designed a data structure that supports the individual operations
outlined above in constant time, independent of both the length of the
state sequence $x$ and the time interval $t$, and requires only
constant time for updates. We call this data structure a {\it binary
  triplet sampler}. Let $\mathit{BTS}(x)$ be a binary triplet sampler
that supports access of $c_{ijk}(x)$ and $\mathit{sample}(x,ijk)$. For
any position $n$, the operation $\mathit{update}(\mathit{BTS}(x), n)$
modifies $\mathit{BTS}(x)$ so that it is valid for
$\mathit{BTS}(x_{\bar{n}})$, where
$x_{\bar{n}} = (x_1,\ldots,\bar{x}_n,\ldots,x_m)$ has the
complementary state at position $n$.

For a binary state sequence $x$ the binary triplet sampler
$\mathit{BTS}(x) = \{A, B, C\}$ is composed of 3 arrays. The array $C$
has 9 values, with $C[a]$ equal to the number of times occurrences of
triplet patterns in $x$ that precede the triplet pattern matching the
binary representation of $0\leq a \leq 8$. So $C[0] = 0$ and
$C[8] = m-2$ always holds. The array $A$ has size $m-2$ and contains
each value $2$ through $m-1$ exactly once. The values in $A$ are
organized as ``segments'' such that the consecutive entries $A[C[a]]$
through $A[C[a+1] - 1]$ all indicate positions $n$ corresponding to
triplet pattern $ijk$ matching the binary representation of $a$. To
perform the operation $c_{ijk}(x)$ the BTS returns
$C[(ijk)+1] - C[ijk]$. To perform the operation
$\mathit{sample}(x,ijk)$, the BTS first samples an integer $u$
uniformly from the half open interval $[0,c_{ijk}(x))$, and then
returns $A[C[ijk] + u]$. Note that since $u$ is sampled uniformly at
random, no additional assumptions are required on how values within
$A$ are organized beyond the contiguity of the 8 segments. Finally,
$B$ is a permutation on positions $1$ through $m$ such that
$A[B[n]] = n$.
%%% Define B

When $x$ is updated by complementing the state at position $n$, three
triplets are modified.
% Up to 7 values in $C$ must change to
% accommodate those modified triplets.
% ({\it e.g.}
% $\mathtt{00100}\rightarrow \mathtt{00000}$ changes $C[1]$ through ).
The values $n$, $n-1$ and $n+1$ must be relocated within $A$ so that
they reside within the appropriate range corresponding to their
modified triplet. Focusing first on position $n$, we assume the
corresponding triplet pattern was modified from $i0k$ (binary
representation of integer $a$) to $i1k$ (representation of
$a+2$). First locate $n$ in $A$ by accessing $b \gets B[n-2]$. Next,
swap the values in $A[b]$ and $A[C[a+1]-1]$ and decrement $C[a+1]$.
Now $n$ resides in the portion of $A$ associated with either the
triplet pattern $i10$ or $i01$, depending on the value of $k$, and in
both cases $n$ is currently in an incorrect location. We swap
$A[C[a+1]]$ and $A[C[a+2]-1]$, moving $n$ from first to the last
location in its current segment. We decrement $C[a+2]$, which extends
the segment corresponding to $a+2$ by one position, effectively
including $n$ in the correct segment. Finally, we set
$B[n-2]\gets A[C[a+2]]$. This procedure required accessing two values
in $B$, making two swaps within $A$, and changing two values in $C$.

The above procedure must be repeated to account for changes to the
triplet patterns for positions $n-1$ and $n+1$. One of these will
require a single swap within $A$, and the other will requre $4$. The
scenario in which the triplet pattern corresponding to position $n$ is
modified from $i1k$ to $i0k$ is similar. Decrements to values $C$
become increments, and swaps within $A$ move values from the end of
segments to the beginning of segments. To summarize, each update to
$x$ at some position $n$ modifies the arrays of the BTS by 7 swaps
within $A$, $7$ changes (increments or decrements) in $C$, and 3
changes in $B$.

\end{document}

%% \begin{enumerate}
%% \item Let $t \gets 0$, and initialize all paths $L_n = \{x_n(0),
%%   k_n=0, T_n=\emptyset, t\}$, for $n=1,\ldots, N.$
%% \item While $t < T$:
%%   \begin{enumerate}
%%   \item Generate $y\sim \text{Exp}(-M_{x(t)x(t)})$, where
%%     $-M_{x(t)x(t)} = \sum_{i,j,k}c_{ijk}(x(t))\lambda_{ijk}$.
%%     \begin{itemize}
%%     \item[If] $t+x < T$ then:
%%       \begin{itemize}
%%       \item Choose triple $ijk \in \{0,1\}^3$ with
%%         probability proportional to $c_{ijk}(x(t))\lambda_{ijk}$.
%%       \item Uniformly sample a position $n$ among the $c_{ijk}(x(t))$ positions having pattern $ijk$.
%%       \item $x(t+y) \gets x(t)[1..n-1]\overline{x(t)_n}x(t)[n+1..N]$.
%%       \item Add jump time to the path of position $n$:
%%         \[
%%         k_n \gets k_n + 1; ~ T_n \gets T_n\cup \{t+x\}.
%%         \]
%%       \end{itemize}
%%     \item[Else:] $x(T) \gets x(t)$.
%%     \end{itemize}
%%   \item $t \gets t+y$
%%   \end{enumerate}
%% \end{enumerate}


% \section{Simulation scheme 1}
% We are going to simulate a full history of epigenome evolution for a
% time interval $[0, t]$.

% \begin{enumerate}
% \item Simulate the starting methylome using a binary-state Markov model
% \item Initialize all paths $L_n = \{s_n(0), k_n=0, T_n=\emptyset, t\}$, for $n=1,\ldots, N.$
% \item (For simplicity, fix the paths $L_1$ and $L_N$ as initialized.) For
%   site $n = 2, \ldots, N-1$, simulate $L_n$ given the current paths of
%   $L_{n-1}$ and $L_{n+1}$:
%   \begin{itemize}
%   \item Collect the time intervals from site $n-1$ and site $n+1$, so
%     that within each of the intervals the states of the neighboring
%     sites are unchanged. Let the intervals be represented by a sorted
%     array $\{t_0, t_1, \cdots, t_M\}$.
%   \item For $m = 1, \ldots, M$:
%     \begin{itemize}
%     \item Let $X$ be a random variable from an exponential
%       distribution, representing the jumping time of the middle site given
%       that the states of its two neighbors are constant.  For a time
%       interval $[t_{m-1}, t_m]$ during which the neighboring sites' states
%       are unchanged, suppose $X\sim \text{Exp}(\lambda)$. The parameter
%       $\lambda$ is a function of current state and the states of the two
%       neighboring sites.
%     \item Let $t = t_{m-1}$, and a sample value of $X=x$.
%     \item While $t +x < t_m$:
%       \begin{enumerate}
%       \item[(1)] Add 1 to the number of jumps $k_n \gets k_n +1$.
%       \item[(2)] Update $T_n \gets T_n\cup\{t+x\}$.
%       \item[(3)] Update $t \gets  t+x$,
%       \item[(4)] Sample another value of $X=x$ from $\text{Exp}(\lambda)$.
%       \end{enumerate}
%     \end{itemize}
%   \end{itemize}
% \item Repeat step 3, until the epigenome summary statistics converge to
%   a stable distribution.
% \end{enumerate}

%% \subsubsection{Scaling parameters}

%% After the estimates are made, we can scale the transition rates and
%% branch lengths to have unit branch length corresponding to 1 expected
%% transition per site.  Given $\lambda_{c}$ according to
%% \eqref{eqn:rel}, the ratios $\frac{\lambda_{010}}{\lambda_{000}}$ and
%% $\frac{\lambda_{001}}{\lambda_{011}}$ uniquely determine the
%% stationary distribution for the epigenome described by a Gibbs measure
%% of the form \eqref{eqn:stationary}. The Gibbs measure for the
%% epigenome sequence, in turn, is equivalent to the Markov chain
%% \eqref{eqn:gibbs2markov}. Given the Markov chain formulation, we can
%% compute the expected frequency of triplet patterns
%% \[
%% p_{ijk} = \pi_i \times T_{ij} \times T_{jk}.
%% \]
%% Then the expected number of changes per position per
%% unit time is $\mu = \sum_{ijk}p_{ijk}\lambda_{ijk}$. We can scale transition
%% rates and branch lengths as follows:
%% \begin{equation}\label{eqn:tidentifiable}
%%   \begin{aligned}
%%     \lambda_{ijk} &\gets \lambda_{ijk}\times \mu \\
%%     t_b &\gets \sum_{m=1}^{M_b} (t_{b,m} - t_{b,m-1}) \times \frac{1}{\mu}.
%%   \end{aligned}
%% \end{equation}
%% %%


%% \paragraph{Method 1:} First, sample a starting state $s_0$ from a
%% Bernoulli distribution with probabilities $(\pi_0, \pi_1)$. Then,
%% propose a number $K$ of jumps from a Poisson distribution with rate
%% parameter $\lambda = \sum\lambda_{ijk}/8$, which is chosen to
%% approximate average mutation rate among different contexts. Given $K$,
%% sample jump times uniformly on the time interval $(0, t)$; In other
%% words, from the Dirichlet distribution with concentration parameters
%% all equal to 1. Therefore, the probability (density) of proposing a
%% specific path $L' = \{s_0, K, \{t_k\}_{k=1}^K, t\}$ is
%% \[
%% q(L') = \pi_{s_0} \frac{\lambda^K \exp(-\lambda)}{K!} \frac{1}{(K-1)!}.
%% \]
%% This is known as an \textit{independence sampler}\cite{}. If the
%% current path at position $n$ is $L_n$, then we accept the proposed
%% path $L'$ with probability
%% \begin{equation}\label{eqn:rejection}
%%   \alpha(L') = \min\left\{\frac{\pi(L', H_{\overline{n}})/q(L')}{\pi(L_n, H_{\overline{n}})/q(L_n)}, 1\right\},
%% \end{equation}
%% where $\pi$ is the complete data likelihood function \eqref{eqn:lik}.

%% \paragraph{Method 2:} The method outlined above uses a proposal
%% distribution that is approximately uniform. This can be highly
%% inefficient, {\it i.e.} lead to a low rate of acceptance, although
%% \citetext{jensen2000probabilistic} used a sampling procedure in the
%% same spirit. If we use more information from the paths at neighboring
%% sites, we may be able to improve sampling efficiency. The neighboring
%% paths $L_{n-1}$ and $L_{n+1}$ partition the evolutionary time interval
%% $(0,t)$ into time segments during which the states at positions $n-1$
%% and $n+1$ do not change.

%% \begin{itemize}
%% \item Collect the time intervals from site $n-1$ and site $n+1$, so
%%   that within each of the intervals the states of the neighboring
%%   sites are unchanged. Let the intervals be represented by a sorted
%%   array $\{t_0, t_1, \cdots, t_M\}$.
%% \item Initialize proposal probability $p\gets 1$.
%% \item For $m = 1, \ldots, M$:
%%   \begin{itemize}
%%   \item Let $X$ be a random variable from an exponential distribution,
%%     representing the jumping time of the middle site given that the states
%%     of its two neighbors are constant.  For a time interval $[t_{m-1},
%%     t_m]$ during which the neighboring sites' states are unchanged,
%%     suppose $X \sim \mathit{Exp}(\lambda_{ijk})$, where $i$ and $k$ are the
%%     states of the two neighboring sites in this time interval, and $j$ is
%%     the starting state of position $n$. Let $f_{\lambda}$ be the p.d.f. of
%%     Exponential distribution $\mathit{Exp}(\lambda)$.
%%   \item Let $t = t_{m-1}$, and a sample value of $X=x$.
%%   \item While $t + x < t_m$:
%%     \begin{enumerate}[label={(\arabic*)}]
%%     \item Update proposal probability $p \gets p\times f_{\lambda_{ijk}}(x)$.
%%     \item Update the state of the center site $j \gets \bar{j}$.
%%     \item Add 1 to the number of jumps $k_n \gets k_n +1$.
%%     \item Update $T_n \gets T_n\cup\{t+x\}$.
%%     \item Update $t \gets  t+x$,
%%     \item Sample another value of $X=x$ from $\mathit{Exp}(\lambda_{ijk})$.
%%     \end{enumerate}
%%   \item Update proposal probability $p \gets p\times \Pr_{\lambda_{ijk}}(X > t_m - t )$.
%%   \end{itemize}
%% \end{itemize}

%% The proposal probability density function $q()$ is thus the product of
%% the appropriate Exponential distribution probability densities for the
%% holding times at position $n$, and is calculated as $p$. The proposal
%% distribution is independent of any current guess of the
%% path. Therefore, this is also an \textit{independence sampler}. The
%% rejection rule stays the same, as in (\ref{eqn:rejection}).

%% \paragraph{Note:} For two versions of complete evolutionary history
%% that only differ at one position, their difference in likelihood is
%% determined by the paths at that position, and two positions to each
%% side, \textit{i.e.} 5 positions in total. Because the total time spent
%% in each triplet context \eqref{eqn:Dijk} is altered at the center
%% position and its two neighboring positions. Let $n$  be the center position.
%% Let $D_{n,c}$ be the total time spent in triplet context $c$ at position $n$
%% in the current instance of evolutionary paths, and let $D'_{n,c}$ be that of
%% the new proposed evolutionary path. Similarly let $J_{n,c}$ and $J'_{n,c}$ be
%% the total number of jumps out of context $c$ at position $n$ in the
%% current and proposed paths. Thus, the ratio of complete data
%% likelihood in acceptance probability \eqref{eqn:rejection} can be
%% computed as
%% \[
%% \frac{\pi(L', H_{\overline{n}})}{\pi(L_n, H_{\overline{n}})} = \prod_{c}\prod_{s=n-1}^{n+1}
%% \lambda_c^{J'_{s,c} - J_{s,c}} \exp(-(D'_{s,c}-D_{s,c})\lambda_c).
%% \]

%% %% JQU: current goal of coding is to make sure after one pass of updates,
%% %% the parameters can be recovered from the updated paths.

%% % \paragraph{Note:} A jump at time $\tau$ within the path $L_{n}$
%% % will affect the probability of all jumps that occur after time $\tau$,
%% % regardless of their position within the epigenome. The is because such
%% % a jump affects $\{c_{ijk}(t)\}$ for any $t > \tau$. Therefore, we
%% % cannot cancel out factors in the likelihood function. However, we may
%% % try to make things easy by only considering the evolutionary paths at
%% % positions $n-2$, $n-1$, $n+1$, and $n+2$.
